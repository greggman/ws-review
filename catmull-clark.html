<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>Catmull-Clark Subdivision Surfaces</title>
  </head>

  <body>
    <canvas width="512" height="512"></canvas>
    <script type="module">
      // inspiration: https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html

      import {
        vec3,
        mat4,
      } from "https://wgpu-matrix.org/dist/3.x/wgpu-matrix.module.js";

      // Q: I would like to pass in a struct as a uniform,
      // but I couldn't get that to work, and converted to an
      // array instead
      var params_DOESNOTWORK = {
        UPDATE_INTERVAL: 20000.0, // Update every <- ms
        time: 0.0,
        timestep: 1.0,
      };
      const params = new Float32Array([200.0, 0.0, 1.0]);
      // Q: the following seems bad since it has to be manually updated
      const params_length = 3 * Float32Array.BYTES_PER_ELEMENT;

      const adapter = await navigator.gpu?.requestAdapter();
      const device = await adapter?.requestDevice();
      if (!device) {
        fail("Fatal error: Device does not support WebGPU.");
      }

      const canvas = document.querySelector("canvas");
      const context = canvas.getContext("webgpu");
      const canvasFormat = navigator.gpu.getPreferredCanvasFormat();
      context.configure({
        device: device,
        format: canvasFormat,
      });

      /** The following tables are precomputed (on the CPU): Niessner 2012:
       * "Feature-adaptive rendering involves a CPU preprocessing step, as well as a
       * GPU runtime component. Input to our algorithm is a base control mesh
       * consisting of vertices and faces, along with optional data consisting
       * of semisharp crease edge tags and hierarchical details. In the CPU
       * preprocessing stage, we use these data to construct tables containing
       * control mesh indices that drive our feature adaptive subdivision process.
       * Since these subdivision tables implicitly encode mesh connectivity, no
       * auxiliary data structures are needed for this purpose. A unique table
       * is constructed for each level of subdivision up to a prescribed maximum,
       * as well as final patch control point index buffers as described in
       * Section 3.2. The base mesh, subdivision tables, and patch index data are
       * uploaded to the GPU, one time only, for subsequent runtime processing.
       * The output of this phase depends only on the topology of the base mesh,
       * crease edges, and hierarchical detail; it is independent of the geometric
       * location of the control points." */

      /** Initial test is a 5-face rectangular pyramid, which has 23 resulting elements
       * after a single subdivision. Only the first 5 points must be populated in
       * the vertices buffer. */

      const vertices_size = 23;
      const vertices_object_size = 4; // float4s (but ignore w coord for now)
      // float3s were fraught with peril (padding)
      const vertices = new Float32Array(vertices_size * vertices_object_size);

      // prettier-ignore
      const base_vertex_positions = new Float32Array([
                        0, 0, 1, 1,   // vertex 0
                        -1, 1, 0, 1,  // vertex 1
                        -1, -1, 0, 1, // vertex 2
                        1, -1, 0, 1,  // vertex 3
                        1, 1, 0, 1,   // vertex 4
                      ]); // use this ONLY to populate (part of) the vertex buffer
      for (var i = 0; i < base_vertex_positions.length; i++) {
        vertices[i] = base_vertex_positions[i];
      }
      // never use base_vertex_positions again

      // Q: Is a flattened 1D array the right way to represent base faces?
      // prettier-ignore
      const base_faces = new Uint32Array([
                        0, 1, 2, // vertices in face 0
                        0, 2, 3, //         ... face 1
                        0, 3, 4, //         ... face 2
                        0, 4, 1, //         ... face 3
                        4, 3, 2, 1, //      ... face 4
                      ]);
      // the following is manually generated tri indexes from base_faces
      // TODO: this could totally be generated programmatically from
      //   base_faces plus base_face_valence
      // prettier-ignore
      const base_triangle_indices = new Uint32Array([
                        0, 1, 2, // vertices in tri 0
                        0, 2, 3, //         ... tri 1
                        0, 3, 4, //         ... tri 2
                        0, 4, 1, //         ... tri 3
                        4, 3, 2, //         ... tri 4
                        4, 2, 1, //         ... tri 5
                      ]);

      const base_face_valence = new Uint32Array([3, 3, 3, 3, 4]);
      // base_face_offset is exclusive_scan('+', base_face_valence)
      // TODO: compute that scan in a compute shader
      const base_face_offset = new Uint32Array([0, 3, 6, 9, 12]);
      const base_faces_count = base_face_valence.length;
      var vertices_write_ptr = base_faces_count;

      // prettier-ignore
      const base_edges = new Uint32Array([
                        0, 5, 2, 6,
                        1, 5, 0, 8,
                        2, 5, 1, 9,
                        0, 6, 3, 7,
                        3, 6, 2, 9,
                        0, 7, 4, 8,
                        4, 7, 3, 9,
                        1, 8, 4, 9,
                      ]);
      const edges_object_size = 4; // (two faces, two edges)
      const base_edges_count = base_edges.length / edges_object_size;

      const base_vertex_valence = new Uint32Array([4, 3, 3, 3, 3]);
      // base_vertex_offset is 2 * exclusive_scan('+', base_vertex_valence)
      // TODO: compute that scan in a compute shader
      const base_vertex_offset = new Uint32Array([0, 8, 14, 20, 26]);
      const base_vertex_count = base_vertex_valence.length;
      const base_vertex_index = new Uint32Array([0, 1, 2, 3, 4]);
      // prettier-ignore
      const base_vertices = new Uint32Array([
                        4, 8, 1, 5, 2, 6, 3, 7,
                        4, 9, 2, 5, 0, 8,
                        3, 6, 0, 5, 1, 9,
                        4, 7, 0, 6, 2, 9,
                        1, 8, 0, 7, 3, 9,
                      ]);

      const perturbInputVerticesModule = device.createShaderModule({
        label: "perturb input vertices module",
        code: /*wgsl*/ `
          struct Params {
            UPDATE_INTERVAL:f32,
            time:f32,
            timestep:f32,
          }
          /* input + output */
          @group(0) @binding(0) var<storage, read_write> vertices: array<vec3f>;
          /* uniform: time */
          @group(0) @binding(1) var<uniform> params: Params;
          @compute @workgroup_size(1) fn perturbInputVerticesKernel(
                   @builtin(global_invocation_id) id: vec3u) {
            let i = id.x;
            let t = params.time;
            let stepsize = 0.1;
            let angle_start = f32(i);
            /* philosophy of animating base vertices:
             *
             * - vertex should not move in aggregate over time
             * - each vertex should move ~differently
             *
             * design: each vertex moves in a "random" direction by a fixed amt
             *         starting direction differs per vertex ("angle_start")
             *         movements cancel each other out over time
             */
            vertices[i] += vec3(stepsize * cos(angle_start + t),
                                stepsize * sin(angle_start + t),
                                stepsize * 0.5 * sin(angle_start + t));
          }
        `,
      });

      /** (1) Calculation of face points
       * Number of faces: base_face_valence.length
       * for each face: new face point = centroid(vertices of current face)
       * Pseudocode:   (note math operations are on vec3f's)
       * parallel for i in [0 .. base_face_valence.length]:
       *   new_faces[i] = [0,0,0]
       *   for j in [base_face_offset[i] .. base_face_offset[i] + base_face_valence[i]]:
       *     new_faces[i] += base_vertex_positions[base_faces[j]
       *   new_faces[i] /= base_face_valence[i]
       */

      const facePointsModule = device.createShaderModule({
        label: "face points module",
        code: /*wgsl*/ `
              /* input + output */
              @group(0) @binding(0) var<storage, read_write> vertices: array<vec3f>;
              /* input */
              @group(0) @binding(1) var<storage, read> base_faces: array<u32>;
              @group(0) @binding(2) var<storage, read> base_face_offset: array<u32>;
              @group(0) @binding(3) var<storage, read> base_face_valence: array<u32>;

              /** Niessner 2012:
                * "The face kernel requires two buffers: one index buffer, whose
                * entries are the vertex buffer indices for each vertex of the face; a
                * second buffer stores the valence of the face along with an offset
                * into the index buffer for the first vertex of each face."
                *
                * implementation above: "index buffer" is base_faces
                *                       "valence of the face" is base_face_valence
                *                       "offset into the index buffer" is base_face_offset
                */

              @compute @workgroup_size(1) fn facePointsKernel(
                @builtin(global_invocation_id) id: vec3u) {
                let i = id.x;
                /* TODO: exit if my index is larger than the size of the input */

                let out = i + ${vertices_write_ptr};
                vertices[out] = vec3f(0,0,0);
                for (var j: u32 = base_face_offset[i]; j < base_face_offset[i] + base_face_valence[i]; j++) {
                  let face_vertex = base_faces[j];
                  vertices[out] += vertices[face_vertex];
                }
                vertices[out] /= f32(base_face_valence[i]);
                // TODO: decide on vec3f or vec4f and set w if so
              }
            `,
      });

      vertices_write_ptr += base_faces_count;

      /** output vertices from face kernel, for debugging:
       * [-0.6666666865348816, 0, 0.3333333432674408, 0]
       * [0, -0.6666666865348816, 0.3333333432674408, 0]
       * [0.6666666865348816, 0, 0.3333333432674408, 0]
       * [0, 0.6666666865348816, 0.3333333432674408, 0]
       * [0, 0, 0, 0]
       */

      /** (2) Calculation of edge points
       * Number of edges: base_edges.length
       * for each edge: new edge point = average(2 neighboring face points, 2 endpoints of edge)
       * Pseudocode:   (note math operations are on vec3f's)
       * parallel for i in [0 .. ?.length]:
       *   new_edges[i] = 0.25 * ( vertices[edge_id] + vertices[edge_id + 1] +
       *                           vertices[edge_id + 2] + vertices[edge_id + 3])
       */

      const edgePointsModule = device.createShaderModule({
        label: "edge points module",
        code: /*wgsl*/ `
                      /* input + output */
                      @group(0) @binding(0) var<storage, read_write> vertices: array<vec3f>;
                      /* input */
                      @group(0) @binding(1) var<storage, read> base_edges: array<vec4u>;

                      /** "Since a single (non-boundary) edge always has two incident faces and vertices,
                       * the edge kernel needs a buffer for the indices of these entities."
                       *
                       * implementation above: "a buffer for the indices of these entities" is base_edges
                       */

                      @compute @workgroup_size(1) fn edgePointsKernel(
                        @builtin(global_invocation_id) id: vec3u) {
                          let i = id.x;
                          /* TODO: exit if my index is larger than the size of the input */

                          let out = i + ${vertices_write_ptr};
                          let edge_id = i;
                          vertices[out] = vec3f(0,0,0);
                          for (var j: u32 = 0; j < 4; j++) {
                            vertices[out] += vertices[base_edges[edge_id][j]];
                          }
                          vertices[out] *= 0.25;
                      }
                    `,
      });

      vertices_write_ptr += base_edges_count;

      /** output "edge" vertices from edge kernel, for debugging
       * 10 | -0.4166666865348816, -0.4166666865348816, 0.4166666865348816, 0
       * 11 | -0.4166666865348816, 0.4166666865348816, 0.4166666865348816, 0
       * 12 | -0.6666666865348816, 0, 0.0833333358168602, 0
       * 13 | 0.4166666865348816, -0.4166666865348816, 0.4166666865348816, 0
       * 14 | 0, -0.6666666865348816, 0.0833333358168602, 0
       * 15 | 0.4166666865348816, 0.4166666865348816, 0.4166666865348816, 0
       * 16 | 0.6666666865348816, 0, 0.0833333358168602, 0
       * 17 | 0, 0.6666666865348816, 0.0833333358168602, 0
       */

      /** (3) Calculation of vertex points
       * This is more involved. References:
       * - https://www.rorydriscoll.com/2008/08/01/catmull-clark-subdivision-the-basics/
       * - https://en.wikipedia.org/wiki/Catmull%E2%80%93Clark_subdivision_surface
       * Big picture:
       * - n is valence of this point
       * - F is the average of all neighboring faces (new face points)
       * - Ve is the average of the other endpoint of all incident edges
       *   - The actual math is "midpoint of all incident edges", but one end of all
       *     those edges is just V (below), so we lump that contribution into the V term
       *   - F and Ve are just listed in the base_vertices table
       * - V is this vertex
       *   - Output is (F + Ve + (n-2) V) / n
       * - If F and Ve points are f_0, f_1, Ve_0, ...:
       *   - Output is [(f_0 + f_1 + ... + Ve_0 + Ve_1 + ...) / n _ (n-2) V] / n
       * Number of vertex points: base_vertex_valence.length
       * Pseudocode:   (note math operations are on vec3f's)
       * parallel for i in [0 .. base_vertex_valence.length]:
       *   new_vertex[i] = [0,0,0]
       *   valence = base_vertex_valence[i]
       *   for j in [base_vertex_offset[i] .. base_vertex_offset[i] + base_vertex_valence[i]]:
       *     new_vertex[i] += vertices[base_vertices[j]]
       *   new_vertex[i] /= base_vertex_valence[i]
       *   new_vertex[i] += (n-2) * base_vertex_index[i]
       *   new_vertex[i] /= base_vertex_valence[i]
       */

      const vertexPointsModule = device.createShaderModule({
        label: "vertex points module",
        code: /*wgsl*/ `
              /* input + output */
              @group(0) @binding(0) var<storage, read_write> vertices: array<vec3f>;
              /* input */
              @group(0) @binding(1) var<storage, read> base_vertices: array<u32>;
              @group(0) @binding(2) var<storage, read> base_vertex_offset: array<u32>;
              @group(0) @binding(3) var<storage, read> base_vertex_valence: array<u32>;
              @group(0) @binding(4) var<storage, read> base_vertex_index: array<u32>;

              /** "We use an index buffer containing the indices of the incident edge and
               * vertex points."
               *
               * implementation above: "a buffer for the indices of these entities" is base_vertices
               */

              @compute @workgroup_size(1) fn vertexPointsKernel(
                @builtin(global_invocation_id) id: vec3u) {
                  let i = id.x;
                  /* TODO: exit if my index is larger than the size of the input */

                  let out = i + ${vertices_write_ptr};
                  let valence = base_vertex_valence[i];
                  vertices[out] = vec3f(0,0,0);
                  for (var j: u32 = base_vertex_offset[i]; j < base_vertex_offset[i] + 2 * base_vertex_valence[i]; j++) {
                    let base_vertex = base_vertices[j];
                    vertices[out] += vertices[base_vertex];
                  }
                  vertices[out] /= f32(valence);
                  vertices[out] += f32(valence - 2) * vertices[base_vertex_index[i]];
                  vertices[out] /= f32(valence);
                  // TODO: decide on vec3f or vec4f and set w if so
              }
            `,
      });

      /** output vertices from vertex kernel, for debugging
       * 18 | -3.725290298461914e-9, 0, 0.5833333134651184, 0
       * 19 | -0.40740740299224854, 0.40740740299224854, 0.18518519401550293, 0
       * 20 | -0.40740740299224854, -0.40740740299224854, 0.18518519401550293, 0
       * 21 | 0.40740740299224854, -0.40740740299224854, 0.18518519401550293, 0
       * 22 | 0.40740740299224854, 0.40740740299224854, 0.18518519401550293, 0
       */

      const drawModule = device.createShaderModule({
        label: "draw module",
        code: `
              struct VertexInput {
                @location(0) pos: vec3f,
                @builtin(vertex_index) vertex_index: u32,
              };

              struct VertexOutput {
                @builtin(position) pos: vec4f,
                @location(0) color: vec4f,
              };

              // @group(0) @binding(0) var<uniform> grid: vec2f;
              // @group(0) @binding(1) var<storage> cellState: array<u32>;

              @vertex
              fn vertexMain(@location(0) pos: vec3f,
                            @builtin(vertex_index) vertex_index: u32) -> VertexOutput {
                var output: VertexOutput;
                /* this janky code is just about fitting things in the viewport
                 * absolutely this should use modelview xforms, etc.
                 *
                 * we're looking at the bottom of a pyramid
                 */
                output.pos = vec4f(pos * 0.5, 1);
                output.pos.z += 0.05; // if this is +, base is within clipping area, shown
                                      // if this is -, base is outside clipping area, clipped
                output.color = vec4f( // this generates 64 different colors
                  0.1 + select(0, 0.3, (vertex_index & 1) != 0) + select(0, 0.6, (vertex_index & 8) != 0),
                  0.1 + select(0, 0.3, (vertex_index & 2) != 0) + select(0, 0.6, (vertex_index & 16) != 0),
                  0.1 + select(0, 0.3, (vertex_index & 4) != 0) + select(0, 0.6, (vertex_index & 32) != 0),
                  0.75 /* partial transparency might aid debugging */);
                return output;
              }

              @fragment
              fn fragmentMain(input: VertexOutput) -> @location(0) vec4f {
                return input.color;
              }
                  `,
      });

      const perturb_pipeline = device.createComputePipeline({
        label: "perturb input vertices compute pipeline",
        layout: "auto",
        compute: {
          module: perturbInputVerticesModule,
        },
      });

      const face_pipeline = device.createComputePipeline({
        label: "face points compute pipeline",
        layout: "auto",
        compute: {
          module: facePointsModule,
        },
      });

      const edge_pipeline = device.createComputePipeline({
        label: "edge points compute pipeline",
        layout: "auto",
        compute: {
          module: edgePointsModule,
        },
      });

      const vertex_pipeline = device.createComputePipeline({
        label: "vertex points compute pipeline",
        layout: "auto",
        compute: {
          module: vertexPointsModule,
        },
      });

      const draw_pipeline = device.createRenderPipeline({
        label: "draw pipeline",
        layout: "auto",
        vertex: {
          module: drawModule,
          entryPoint: "vertexMain",
          buffers: [
            {
              // Buffer 0
              arrayStride: 16,
              attributes: [
                {
                  shaderLocation: 0, // position
                  format: "float32x3",
                  offset: 0,
                },
              ],
            },
            // could add more buffers here
          ],
        },
        fragment: {
          module: drawModule,
          entryPoint: "fragmentMain",
          targets: [
            {
              format: canvasFormat,
            },
          ],
        },
      });

      // create buffers on the GPU to hold data
      // read-only inputs:
      const base_faces_buffer = device.createBuffer({
        label: "base faces buffer",
        size: base_faces.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_faces_buffer, 0, base_faces);

      const base_edges_buffer = device.createBuffer({
        label: "base edges buffer",
        size: base_edges.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_edges_buffer, 0, base_edges);

      const base_face_offset_buffer = device.createBuffer({
        label: "face offset",
        size: base_face_offset.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_face_offset_buffer, 0, base_face_offset);

      const base_face_valence_buffer = device.createBuffer({
        label: "face valence",
        size: base_face_valence.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_face_valence_buffer, 0, base_face_valence);

      const base_vertices_buffer = device.createBuffer({
        label: "base vertices buffer",
        size: base_vertices.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_vertices_buffer, 0, base_vertices);

      const base_vertex_offset_buffer = device.createBuffer({
        label: "vertex offset",
        size: base_vertex_offset.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(
        base_vertex_offset_buffer,
        0,
        base_vertex_offset
      );

      const base_vertex_valence_buffer = device.createBuffer({
        label: "vertex valence",
        size: base_vertex_valence.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(
        base_vertex_valence_buffer,
        0,
        base_vertex_valence
      );

      const base_vertex_index_buffer = device.createBuffer({
        label: "vertex index",
        size: base_vertex_index.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_vertex_index_buffer, 0, base_vertex_index);

      const base_triangle_indices_buffer = device.createBuffer({
        label: "base triangle indices",
        size: base_triangle_indices.byteLength,
        usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(
        base_triangle_indices_buffer,
        0,
        base_triangle_indices
      );

      const params_buffer = device.createBuffer({
        label: "params buffer",
        size: params_length,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(params_buffer, 0, params);

      // vertex buffer is both input and output
      const vertices_buffer = device.createBuffer({
        label: "vertex buffer",
        size: vertices.byteLength,
        usage:
          GPUBufferUsage.STORAGE |
          GPUBufferUsage.VERTEX |
          GPUBufferUsage.COPY_DST |
          GPUBufferUsage.COPY_SRC,
      });
      device.queue.writeBuffer(vertices_buffer, 0, vertices);

      /** and the mappable output buffer (I believe that "mappable" is the only way to read from GPU->CPU) */
      const mappable_result_buffer = device.createBuffer({
        label: "mappable result buffer",
        size: vertices.byteLength,
        usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
      });

      /** Set up bindGroups per compute kernel to tell the shader which buffers to use */
      const perturb_bindGroup = device.createBindGroup({
        label: "bindGroup for perturb input vertices kernel",
        layout: perturb_pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: vertices_buffer } },
          { binding: 1, resource: { buffer: params_buffer } },
        ],
      });

      const face_bindGroup = device.createBindGroup({
        label: "bindGroup for face kernel",
        layout: face_pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: vertices_buffer } },
          { binding: 1, resource: { buffer: base_faces_buffer } },
          { binding: 2, resource: { buffer: base_face_offset_buffer } },
          { binding: 3, resource: { buffer: base_face_valence_buffer } },
        ],
      });

      const edge_bindGroup = device.createBindGroup({
        label: "bindGroup for edge kernel",
        layout: edge_pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: vertices_buffer } },
          { binding: 1, resource: { buffer: base_edges_buffer } },
        ],
      });

      const vertex_bindGroup = device.createBindGroup({
        label: "bindGroup for vertex kernel",
        layout: vertex_pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: vertices_buffer } },
          { binding: 1, resource: { buffer: base_vertices_buffer } },
          { binding: 2, resource: { buffer: base_vertex_offset_buffer } },
          { binding: 3, resource: { buffer: base_vertex_valence_buffer } },
          { binding: 4, resource: { buffer: base_vertex_index_buffer } },
        ],
      });

      async function renderLoop() {
        /* Q: Is this the right way to set up a render loop,
         *, e.g., the right things are inside it and outside it? */
        /* Q: is "async" OK? It has an async fn within it. */
        // Encode commands to do the computation
        const encoder = device.createCommandEncoder({
          label:
            "overall computation (perturb, face, edge, vertex) + graphics encoder",
        });

        const perturb_pass = encoder.beginComputePass({
          label: "perturb input vertices kernel compute pass",
        });
        perturb_pass.setPipeline(perturb_pipeline);
        perturb_pass.setBindGroup(0, perturb_bindGroup);
        perturb_pass.dispatchWorkgroups(base_vertex_positions.length);
        perturb_pass.end();

        const face_pass = encoder.beginComputePass({
          label: "face kernel compute pass",
        });
        face_pass.setPipeline(face_pipeline);
        face_pass.setBindGroup(0, face_bindGroup);
        face_pass.dispatchWorkgroups(base_faces_count);
        face_pass.end();

        const edge_pass = encoder.beginComputePass({
          label: "edge kernel compute pass",
        });
        edge_pass.setPipeline(edge_pipeline);
        edge_pass.setBindGroup(0, edge_bindGroup);
        edge_pass.dispatchWorkgroups(base_edges_count);
        edge_pass.end();

        const vertex_pass = encoder.beginComputePass({
          label: "vertex kernel compute pass",
        });
        vertex_pass.setPipeline(vertex_pipeline);
        vertex_pass.setBindGroup(0, vertex_bindGroup);
        vertex_pass.dispatchWorkgroups(base_vertex_count);
        vertex_pass.end();

        // Encode a command to copy the results to a mappable buffer.
        // this is (from, to)
        encoder.copyBufferToBuffer(
          vertices_buffer,
          0,
          mappable_result_buffer,
          0,
          mappable_result_buffer.size
        );

        const render_pass = encoder.beginRenderPass({
          colorAttachments: [
            {
              view: context.getCurrentTexture().createView(),
              loadOp: "clear",
              clearValue: { r: 0, g: 0, b: 0.4, a: 1.0 },
              storeOp: "store",
            },
          ],
        });

        // Now render those tris.
        render_pass.setPipeline(draw_pipeline);
        // we're not passing anything in yet, no bind group
        //         pass.setBindGroup(0, bindGroups[step % 2]);
        render_pass.setVertexBuffer(0, vertices_buffer);
        render_pass.setIndexBuffer(base_triangle_indices_buffer, "uint32");
        const start_idx = 0; // this is just to draw a different set of tris
        const end_idx = base_triangle_indices.length;
        render_pass.drawIndexed(
          end_idx - start_idx,
          1 /* instance */,
          start_idx
        );

        // End the render pass and submit the command buffer
        render_pass.end();

        // Finish encoding and submit the commands
        const commandBuffer = encoder.finish();
        device.queue.submit([commandBuffer]);

        // Read the results
        await mappable_result_buffer.mapAsync(GPUMapMode.READ);
        const result = new Float32Array(
          mappable_result_buffer.getMappedRange().slice()
        );
        mappable_result_buffer.unmap();

        console.log("base vertex positions", vertices);
        console.log("final vertex buffer", result);
        console.log("time", params[1]); //// params.timestep);
        ////        params.time += params.timestep;
        params[1] += params[2];
        device.queue.writeBuffer(params_buffer, 0, params);
      }
      renderLoop(); // render first frame right away

      // Schedule renderLoop() to run repeatedly
      setInterval(renderLoop, params[0]); //// params.UPDATE_INTERVAL);

      function fail(msg) {
        // eslint-disable-next-line no-alert
        alert(msg);
      }
    </script>
  </body>
</html>
