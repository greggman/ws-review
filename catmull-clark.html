<!doctype html>

<html>

<head>
  <meta charset="utf-8">
  <title>Catmull-Clark Subdivision Surfaces</title>
</head>

<body>
  <canvas width="512" height="512"></canvas>
  <script type="module">
    // from https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html
    async function main() {
      const adapter = await navigator.gpu?.requestAdapter();
      const device = await adapter?.requestDevice();
      if (!device) {
        fail('Fatal error: Device does not support WebGPU.');
        return;
      }

      const base_vertices = new Uint32Array([0, 1, 2, 3, 4]);
      // note the following are float3s (x, y, z)
      const base_vertex_positions = new Float32Array([
        0, 0, 1,   // vertex 0
        -1, 1, 0,  // vertex 1
        -1, -1, 0, // vertex 2
        1, -1, 0,  // vertex 3
        1, 1, 0    // vertex 4
      ]);
      // Q: Is a flattened 1D array the right way to represent base faces?
      const base_faces = new Uint32Array([
        0, 1, 2,   // vertices in face 0
        0, 2, 3,   //         ... face 1
        0, 3, 4,   //         ... face 2
        0, 4, 1,   //         ... face 3
        4, 3, 2, 1 //         ... face 4
      ]);
      const base_valence = new Uint32Array([3, 3, 3, 3, 4]);
      // base_offset is exclusive_scan('+', base_valence)
      // TODO: compute that scan in a compute shader
      const base_offset = new Uint32Array([0, 3, 6, 9, 12]);

      // (1) Calculation of face points
      // Number of faces: base_valence.length
      // for each face: new face point = centroid(vertices of current face)
      // Pseudocode:   (note math operations are on vec3f's)
      // parallel for i in [0 .. base_valence.length]:
      //   new_faces[i] = [0,0,0]
      //   for j in [base_offset[i] .. base_offset[i] + base_valence[i]]:
      //     vertex_position = base_faces[j]   // get 3 floats
      //     new_faces[i] += base_vertex_positions[vertex_position]
      //   new_faces[i] /= base_valence[i]

      const facePointsModule = device.createShaderModule({
        label: 'face points module',
        code: /*wgsl*/`
        /* output */
        @group(0) @binding(0) var<storage, read_write> new_faces: array<vec3f>;
        /* input */
        @group(0) @binding(1) var<storage, read> base_faces: array<vec3f>;
          /*
        @group(0) @binding(2) var<storage, read> base_vertex_positions: array<vec3f>;
        @group(0) @binding(3) var<storage, read> base_offset: array<u32>;
        @group(0) @binding(4) var<storage, read> base_valence: array<u32>;
          */

        @compute @workgroup_size(1) fn facePointsKernel(
          @builtin(global_invocation_id) id: vec3u) {
            let i = id.x;
            /* initial kernel: just copy input faces to output faces */
            new_faces[i] = base_faces[i];
        }
      `,
      });

      const pipeline = device.createComputePipeline({
        label: 'face points compute pipeline',
        layout: 'auto',
        compute: {
          module: facePointsModule,
        },
      });

      // create buffers on the GPU to hold data
      // start with inputs
      const base_faces_buffer = device.createBuffer({
        label: 'base faces',
        size: base_faces.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_faces_buffer, 0, base_faces);

      const base_vertex_positions_buffer = device.createBuffer({
        label: 'base vertex positions',
        size: base_vertex_positions.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_vertex_positions_buffer, 0, base_vertex_positions);

      const base_offset_buffer = device.createBuffer({
        label: 'base offset',
        size: base_offset.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_offset_buffer, 0, base_offset);

      const base_valence_buffer = device.createBuffer({
        label: 'base valence',
        size: base_valence.byteLength,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(base_valence_buffer, 0, base_valence);

      // now the output buffer
      const new_faces_buffer = device.createBuffer({
        label: 'new faces',
        size: base_faces.byteLength, /* TODO: should this be dynamic, etc.? */
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
      });

      // and the mappable output buffer (TODO: understand need for this)
      const mappable_result_buffer = device.createBuffer({
        label: 'mappable result buffer',
        size: base_faces.byteLength,
        usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
      });

      // Setup a face bindGroup to tell the shader which
      // buffers to use for the face computation
      const face_bindGroup = device.createBindGroup({
        label: 'bindGroup for face kernel',
        layout: pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: new_faces_buffer } },
          { binding: 1, resource: { buffer: base_faces_buffer } },
          /*
          { binding: 2, resource: { buffer: base_vertex_positions_buffer } },
          { binding: 3, resource: { buffer: base_offset_buffer } },
          { binding: 4, resource: { buffer: base_valence_buffer } }, */
        ],
      });

      // Encode commands to do the computation
      const encoder = device.createCommandEncoder({
        label: 'face kernel encoder',
      });
      const pass = encoder.beginComputePass({
        label: 'face kernel compute pass',
      });
      pass.setPipeline(pipeline);
      pass.setBindGroup(0, face_bindGroup);
      pass.dispatchWorkgroups(base_vertices.length);
      pass.end();

      // Encode a command to copy the results to a mappable buffer.
      encoder.copyBufferToBuffer(new_faces_buffer, 0, mappable_result_buffer, 0, mappable_result_buffer.size);

      // Finish encoding and submit the commands
      const commandBuffer = encoder.finish();
      device.queue.submit([commandBuffer]);

      // Read the results
      await mappable_result_buffer.mapAsync(GPUMapMode.READ);
      const result = new Float32Array(mappable_result_buffer.getMappedRange().slice());
      mappable_result_buffer.unmap();

      console.log('base vertex positions', base_vertex_positions);
      console.log('result', result);
    }

    function fail(msg) {
      // eslint-disable-next-line no-alert
      alert(msg);
    }

    main();
  </script>
</body>

</html>